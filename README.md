# -MACHINE-LEARNING---Multimodal-Audio-Visual-Lip-Reading-Web-Platform
A full-stack web application that integrates AV-HuBERT, a state-of-the-art audio-visual speech recognition model developed by Meta, to enable lip-reading and transcription from uploaded videos. 

# Features
• A multimodal pipeline using Python, PyTorch, OpenCV, and FFmpeg for audio/visual preprocessing, model inference, and transcript generation.
• A PHP/MySQL backend for user management, data persistence, and real-time feedback collection; frontend built with HTML, CSS, JavaScript for transcript editing and data visualization.
• Enabled users to review, annotate, and correct transcriptions, contributing to the creation of high-quality datasets for future model fine-tuning.
• Integrated support for GDPR compliance, including data ownership, deletion, and consent tracking.
• Conducted extensive testing on non-frontal views, noisy audio, and lip-only inputs, demonstrating model robustness and highlighting limitations in deepfake detection and homophone disambiguation.

# User dashboard
![image](https://github.com/user-attachments/assets/4f901326-ecb6-4087-a111-140a0f9f0a3a)

# AV-HuBERT model for transcript generation
![image](https://github.com/user-attachments/assets/e5a3e46c-2faf-4497-a94b-fbb45e86110e)

![image](https://github.com/user-attachments/assets/a1c332e3-2502-451b-9bab-23a7acd2a0ef)

![image](https://github.com/user-attachments/assets/82a85dae-2779-498a-87ce-1e8c5143e485)

# Transcript correction
![image](https://github.com/user-attachments/assets/733ebf54-7c1d-4610-9089-f3df1246d86a)
